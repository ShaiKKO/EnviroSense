# Project: Visualize, Architect, and Implement Scalable EnviroSense Core & Integrate Active Learning

**Overarching Goal:** First, create a comprehensive visualization of the proposed scalable EnviroSense platform. Then, refactor the EnviroSense simulation core to embody this visualized architecture, focusing on production-intent quality for foundational elements. This includes defining, documenting, and using the new `UniversalSensorReading` Avro schema for data exchange (suitable for training a variety of AI models like CNNs, RNNs, SVMs, etc.). Finally, integrate and test the `ActiveLearningManager` within this robust and scalable system.

---
## Phase 0: Comprehensive System Architecture Visualization
*Objective: Create a detailed markdown document with Mermaid diagrams to visualize the entire proposed scalable EnviroSense platform, including its core components, interactions, key data structures passed, links to the physics engine, the Main_Platform, and product-specific views like Grid Guardian. This document will serve as the architectural blueprint for subsequent phases.*

*   **Task 0.1: Define Scope and Key Diagrams for Visualization Document.**
    *   Identify the key architectural views required (e.g., overall system context, component breakdown, data flow for simulation and ML, product-specific configurations, detailed physics engine interaction, ALM loop).
    *   List the specific diagrams (using Mermaid) needed for each view.
    *   Specify that diagrams should, where appropriate, indicate the structure or key fields of data being exchanged (e.g., `Environment3DState` attributes, `UniversalSensorReading` fields).
*   **Task 0.2: Create Core Component Interaction Diagram.**
    *   Visualize relationships between: `ProductRegistry`, `ProductConfiguration`, `VirtualGridGuardian`, new `BaseSensor` (highlighting `measure`/`apply_compensation` flow and sensor dependencies), `ModularPhysicsEngine` (conceptual interaction with `PhysicsModule`s), `Environment3DState`, `ScenarioTemplate`, `BaseScenario`, and `UniversalSensorReading.avsc` as the data format.
    *   Clearly label interactions with the names of key data structures being passed (e.g., "Configured Sensor Suite" from `ProductRegistry` to `VirtualGridGuardian`, "Sensor Measurement Request" to `BaseSensor`, "Compensated Reading (UniversalSensorReading format)" from `BaseSensor`).
*   **Task 0.3: Detail Physics Engine Integration Diagram.**
    *   Illustrate how `Environment3DState` is populated/updated by the `ModularPhysicsEngine`.
    *   Show how different `PhysicsModule`s (e.g., `ChemicalDispersionModule`, `ThermalModule`, `AcousticPropagationModule`) contribute to `Environment3DState`.
    *   Detail how `BaseSensor` instances query `Environment3DState` during their `measure` method and what kind of structured data (e.g., "query for chemical concentration at point/volume") they expect in return from `Environment3DState`.
*   **Task 0.4: Illustrate Product-Specific Configuration (Example: Grid Guardian).**
    *   Diagram how "Grid Guardian" is configured via `ProductRegistry`.
    *   Show its specific `sensor_suite`, relevant `PhysicsModule`s, and how `operational_logic` might apply.
    *   Highlight how `ProductConfiguration` data (e.g., `sensor_suite` list, `physics_modules` list) is used by other components.
*   **Task 0.5: Diagram Data Flow for Simulation and ML Training.**
    *   Trace data from scenario execution -> `VirtualGridGuardian` interaction with `Environment3DState` and sensors -> `UniversalSensorReading` data generation (by `MLDataGenerator`) -> conceptual storage -> consumption by ML models.
    *   Explicitly show the `UniversalSensorReading` structure as it's generated by `MLDataGenerator` and conceptually consumed by ML models.
*   **Task 0.6: Visualize `ActiveLearningManager` Loop within the New Architecture.**
    *   Diagram ALM's interaction with `ModelInterface`, `ScenarioRepositoryInterface`, and `MLDataGenerator`, emphasizing how it leverages the product-aware and scalable components.
    *   Indicate the structure of `ModelPerformanceData` consumed by ALM and the `ScenarioDefinition` (or deltas) it might suggest.
*   **Task 0.7: Context Diagram with Main_Platform.**
    *   Create a high-level diagram showing how this simulation and ML training system (the "digital twin") interfaces with or fits into the broader "Main_Platform" or "EnviroSense Core Platform."
    *   Show primary data exchange points/formats with the Main_Platform if applicable at this stage.
*   **Task 0.8: Compile and Review Visualization Document.**
    *   Assemble all diagrams and explanatory text into a single markdown document (e.g., `envirosense/docs/architecture/envirosense_scalable_platform_architecture.md`).
    *   Ensure clarity, consistency, and completeness for easy demonstration to others.
    *   Ensure diagrams effectively communicate both component interactions and the nature of the data flowing between them.

---
## Phase 1: Robust Foundational Refactoring & Universal Schema Definition (Production-Intent)
*(Guided by the architectural blueprint from Phase 0)*
*Objective: Implement the new scalable architecture for sensors, product configurations, core simulation components, and define and document the universal Avro data schema.*

1.  **Universal Sensor Abstraction Layer:**
    *   **Task 1.1: Define `SensorCapability` Enum.**
        *   Location: e.g., `envirosense/simulation_engine/sensors/capabilities.py` (new file).
        *   Content: Enum defining standardized sensor capabilities (e.g., `CHEMICAL_DETECTION`, `THERMAL_IMAGING`, `ACOUSTIC_MONITORING`, etc.).
    *   **Task 1.2: Implement New `BaseSensor` ABC.**
        *   Location: e.g., `envirosense/simulation_engine/sensors/universal_base_sensor.py` (new file, or refactor existing `base.py` carefully).
        *   Content: Abstract Base Class with `__init__(self, sensor_id: str, config: Dict[str, Any])` and abstract methods: `_define_capabilities(self) -> List[SensorCapability]`, `_define_dependencies(self) -> Dict[str, List[str]]`, `measure(self, environment_state: Any, other_sensors: Dict[str, 'BaseSensor']) -> Dict[str, Any]`, `apply_compensation(self, raw_value: Any, compensating_values: Dict[str, Any]) -> Any`, `_load_calibration(self) -> Dict[str, Any]`.
    *   **Task 1.3: Refactor Key "Grid Guardian" Sensors.**
        *   Target sensors for full refactoring:
            *   `VOCSensorArray` (from `environmental.py`)
            *   `TemperatureHumiditySensor` (from `environmental.py` - will be a dependency)
            *   `ThermalCameraSensor` (from `infrastructure.py`)
            *   `InternalBoardTemperatureSensor` (from or to be added to `system.py` - will be a dependency; if a suitable one doesn't exist, a simple version will be created/stubbed then refactored).
            *   `AcousticSensor` (from `infrastructure.py`)
            *   `WindSensor` (from `environmental.py` - will be a dependency, likely an Anemometer; if a suitable one doesn't exist, a simple version will be created/stubbed then refactored).
        *   Action: Modify these sensor classes to inherit from the new `universal_base_sensor.BaseSensor`.
            *   Implement all abstract methods (`_define_capabilities`, `_define_dependencies`, `measure`, `apply_compensation`, `_load_calibration`).
            *   **Implement functional `apply_compensation()` for three distinct pairs:**
                1.  `VOCSensorArray` using readings from `TemperatureHumiditySensor`.
                2.  `ThermalCameraSensor` using readings from `InternalBoardTemperatureSensor`.
                3.  `AcousticSensor` using readings from `WindSensor` (e.g., to filter wind noise or adjust sensitivity based on wind speed).
            *   Other refactored sensors (if any are touched beyond these for basic compatibility) can have pass-through compensation logic initially.
    *   **Task 1.4: Unit Tests for Refactored Sensors.**
        *   Update existing tests and create new ones to specifically validate the new interface, including the three specified compensation logics and dependency declarations.

2.  **Product Configuration System:**
    *   **Task 2.1: Implement `ProductConfiguration` Dataclass and `ProductRegistry` Singleton.**
        *   Location: e.g., `envirosense/config/product_registry.py` (new file).
        *   Content: As per the architectural example, `_load_configurations` should parse YAML/JSON files from a defined directory.
    *   **Task 2.2: Create Initial Product Configuration File for "Grid Guardian".**
        *   Location: e.g., `envirosense/config/products/grid_guardian.yaml` (new file/directory).
        *   Content: Define `product_type: grid_guardian`, its `sensor_suite` (listing all sensors from Task 1.3), a conceptual list for `physics_modules` and `ml_models`, and any initial `operational_logic` or `performance_constraints` as placeholders.

3.  **`VirtualGridGuardian` Refactoring (Product-Aware):**
    *   **Task 3.1: Modify `VirtualGridGuardian` (`envirosense/simulation_engine/sensors/grid_guardian.py`).**
        *   Update `__init__` to accept `product_type: str`.
        *   Use the `ProductRegistry` to fetch the `ProductConfiguration`.
        *   Instantiate sensors from the `sensor_suite` in the product config, using the new `BaseSensor` constructor.
        *   Update the main sampling loop to correctly orchestrate `measure()` calls for the new `BaseSensor` interface, passing the `other_sensors` dictionary to facilitate compensation.
    *   **Task 3.2: Update `VirtualGridGuardian` Unit Tests** to reflect product-aware instantiation and the new sensor interaction model.

4.  **Universal Data Schema Definition, Documentation & Utility Preparation:**
    *   **Task 4.1: Define `UniversalSensorReading.avsc` Schema.**
        *   Location: e.g., `envirosense/schemas/avro/universal/UniversalSensorReading.avsc` (new file/directory).
        *   Content: Schema defining `timestamp`, `product_type`, `device_id`, `location`, and an array of `SensorReading` sub-records (each with `sensor_id`, `sensor_type`, `capability`, `value` (union type), `unit`, `quality_indicators`, `compensations_applied`).
    *   **Task 4.2: Document `UniversalSensorReading.avsc` Schema.**
        *   Create a markdown document (e.g., `envirosense/docs/schemas/universal_sensor_reading_spec.md`) detailing the schema structure, fields, expected content, and usage examples for different sensor types.
    *   **Task 4.3: Sensor Output Alignment (Python Dictionaries).**
        *   Ensure the `measure()` method of refactored sensors (Task 1.3) returns Python dictionaries directly serializable into the `SensorReading` sub-record of `UniversalSensorReading.avsc`.
    *   **Task 4.4: `VirtualGridGuardian` Output Alignment (Python Dictionaries).**
        *   Ensure `VirtualGridGuardian.generate_training_sample()` (or its primary data-producing method) returns a Python dictionary precisely matching the *structure* of `UniversalSensorReading.avsc`.
    *   **Task 4.5: Enhance/Verify `avro_io.py` Utilities.**
        *   Location: `envirosense/utils/avro_io.py`.
        *   Ensure robust functions for loading named schemas, serializing Python dictionaries (conforming to `UniversalSensorReading.avsc`) to Avro data files/bytes, and deserializing Avro data files/bytes back into Python dictionaries.

5.  **Modular Physics Engine & Scenario Templates (Interfaces & Stubs - Foundational):**
    *   **Task 5.1: Implement `PhysicsModule` ABC.**
        *   Location: e.g., `envirosense/simulation_engine/physics/modular_engine.py` (new file).
        *   Content: Abstract Base Class with `applies_to_product(self, product_type: str) -> bool` and `update(self, state: Environment3DState, dt: float) -> None`.
    *   **Task 5.2: Create Stub Implementations** for different physics modules (e.g., `ChemicalDispersionModule`, `WaterFlowModule`, `AcousticPropagationModule`).
    *   **Task 5.3: Implement `ScenarioTemplate` ABC.**
        *   Location: e.g., `envirosense/simulation_engine/scenarios/templates.py` (new file).
        *   Content: Abstract Base Class with `instantiate(self, product_type: str, parameters: Dict[str, Any]) -> BaseScenario`.
    *   **Task 5.4: Create Stub Implementations** for scenario templates (e.g., `EnvironmentalDegradationTemplate`, `IntrusionDetectionTemplate`).

---
## Phase 2: `ActiveLearningManager` Initial Integration & Testing (with Avro Serialization)
*(Builds upon the refactored components from Phase 1)*
*Objective: Test the `ActiveLearningManager`'s core logic, with the mock `MLDataGenerator` producing and the `LocalModelInterface` consuming actual Avro data based on the `UniversalSensorReading` schema.*

*   **Task 6.1: Create `run_active_learning_loop_concrete.py` Script.**
    *   Location: `envirosense/simulation_engine/ml_training/examples/run_active_learning_loop_concrete.py` (new file).
*   **Task 6.2: Implement Mock `MLDataGenerator` (Producing Avro Output).**
    *   Its `generate_training_dataset()` method will:
        *   Receive scenario definitions and `product_type`.
        *   Internally generate Python dictionaries matching `UniversalSensorReading.avsc`.
        *   If `output_format == "avro"`, use `avro_io.py` to serialize these dicts to an Avro file (e.g., `alm_mock_output.avro`) using the `UniversalSensorReading.avsc` schema and return the file path.
*   **Task 6.3: Implement Adapted `LocalModelInterface` (Consuming Avro Input).**
    *   Its `get_model_performance_feedback()` method will, if given a file path, use `avro_io.py` to load and deserialize the Avro data.
    *   Its `_preprocess_data()` method will be updated to parse `UniversalSensorReading`-structured dictionaries.
*   **Task 6.4: Create Dummy Model (`dummy_model.joblib`).**
    *   Train it on features derivable from the `UniversalSensorReading` structure.
*   **Task 6.5: Generate Initial Evaluation Data (as an Avro file).**
    *   Create a small set of Python dictionaries structured as `UniversalSensorReading` records, then serialize to an Avro file (e.g., `initial_eval_data.avro`) using `avro_io.py`.
*   **Task 6.6: Instantiate Components in the Script (with Parameter Logging).**
    *   Instantiate `ProductRegistry`, `PostgresScenarioRepository`, the adapted `LocalModelInterface`, Mock `MLDataGenerator`, `RealTimeSensorPrioritizationStrategy`, and `ActiveLearningManager`.
    *   Print key parameters of the instantiated `RealTimeSensorPrioritizationStrategy`.
    *   The script will need to specify a `product_type` (e.g., "grid_guardian") for product-aware components.
*   **Task 6.7: Run the ALM Cycle (with Text-Based Output for ALM decisions).**
    *   Include print statements to summarize identified weak spots, scenario suggestions, and targeted sample generation details.
*   **Task 6.8: Test Feedback on New Samples.**
    *   Use the adapted `LocalModelInterface` to process Avro data generated by the mock `MLDataGenerator`.